{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901c861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from graph_tool.all import *\n",
    "import networkx as nx\n",
    "import collections\n",
    "import scipy as sp\n",
    "\n",
    "from scipy.sparse import dok_matrix\n",
    "\n",
    "import modules\n",
    "\n",
    "openmp_set_num_threads(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8301817",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89d9b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_lone_vertices(g):\n",
    "    \"\"\"\n",
    "    Return a GraphView that filters out unconnected vertices.\n",
    "    \"\"\"\n",
    "    vmask = g.new_vertex_property(\"bool\")\n",
    "    vmask.fa = g.degree_property_map(\"total\").fa != 0\n",
    "\n",
    "    return GraphView(g, vfilt = vmask)\n",
    "\n",
    "def all_path_of_length(g, source, target, length, only_unique=False):\n",
    "    for path in all_paths(g, source, target, cutoff=length, edges=False):\n",
    "        if len(path) == length:\n",
    "            if only_unique:\n",
    "                if len(path) == len(set(path)):\n",
    "                    yield path\n",
    "            else:\n",
    "                yield path\n",
    "\n",
    "def make_structured_edge_graph(g, l=1):\n",
    "    #for ease we make a reverse copy since adjacency a_ij in graph-tool gives presence of edge from j to i\n",
    "    g_reverse = GraphView(g, reversed=True)\n",
    "\n",
    "    #finding nodes connected through paths of length l\n",
    "    c_paths = dict(dok_matrix(adjacency(g_reverse, weight=None)**l))\n",
    "\n",
    "    reached=set()\n",
    "    path_nodes = [] #we fill this list with paths of length l we eventually want to make nodes out of in path space\n",
    "    for i in c_paths.keys():\n",
    "        source = i[0]\n",
    "        target = i[1]\n",
    "        #if source!=target: #no cycle path\n",
    "        for path in all_path_of_length(g, source, target, l+1):\n",
    "            path_nodes.append(path)\n",
    "\n",
    "    reached = reached.union(set([item for l in path_nodes for item in l]))        \n",
    "    unreached = set(g.get_vertices()).difference(reached)\n",
    "\n",
    "    sub_l_path_nodes = [] #here we store paths shorter than l for which we will make isolated nodes in path space\n",
    "    for sub_l in np.arange(l-1,0,-1): #we check if we can reach the nodes not reached with pathlength l with paths of length l,...,1\n",
    "        sub_l_paths = dok_matrix(adjacency(g, weight=None)**sub_l) #here we use the non-reversed g because it will be easier to find the sources for a given target\n",
    "        sub_l_reachable_nodes = set([item for tup in sub_l_paths.keys() for item in tup])\n",
    "        for node in unreached.intersection(sub_l_reachable_nodes):\n",
    "            unreached.remove(node)\n",
    "            sources = []\n",
    "            for temp_link in dict(sub_l_paths[node]).keys():\n",
    "                sources.append(temp_link[1])\n",
    "            for source in sources:\n",
    "                for path in all_shortest_paths(g, source, node):\n",
    "                    sub_l_path_nodes.append(path)\n",
    "\n",
    "    #adding isolated nodes\n",
    "    sub_l_path_nodes += list(unreached)\n",
    "\n",
    "    #adding the nodes directly in a structured dict of lists representation of a network (input for the structural controllability code)\n",
    "    structured_path_matrix = {}\n",
    "    for i in path_nodes:\n",
    "        str_i = '-'.join(map(str, i)) #represent a path a-b-c as string 'a-b-c' just for convenience in debugging\n",
    "        structured_path_matrix.setdefault(str_i,[])\n",
    "        for j in path_nodes:\n",
    "            if np.array_equal(i[1:],j[:-1]):\n",
    "            #if any(np.array_equal(i[k:],j[:-k]) for k in range(1, len(i)-1)):\n",
    "                str_j = '-'.join(map(str, j))\n",
    "                structured_path_matrix.setdefault(str_i,[])\n",
    "                structured_path_matrix[str_i].append(str_j)\n",
    "\n",
    "    for i in sub_l_path_nodes:\n",
    "        if type(i) == int or type(i) == np.int64:\n",
    "            structured_path_matrix.setdefault(str(i),[])\n",
    "        else:\n",
    "            str_i = '-'.join(map(str, i))\n",
    "            structured_path_matrix.setdefault(str_i,[])\n",
    "    \n",
    "    return structured_path_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3487190",
   "metadata": {},
   "source": [
    "# Consultant network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19102517",
   "metadata": {},
   "source": [
    "data downloaded from: http://opsahl.co.uk/tnet/datasets/Cross_Parker-Consulting_info.txt (last accessed 11 nov 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e718329a",
   "metadata": {},
   "source": [
    "## Read in data and make network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b4613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_tool.all import *\n",
    "\n",
    "#opens your file in mode \"read\"\n",
    "f = open(\"consulting_net.txt\",\"r\")\n",
    "#splits each line into a list of integers\n",
    "lines = [[(int(n)-1) for n in x.split()[:-1]] for x in f.readlines()]\n",
    "#closes the file\n",
    "f.close()\n",
    "\n",
    "#makes the graph\n",
    "g = Graph()\n",
    "#adds enough vertices (the \"1 + \" is for position 0)\n",
    "g.add_vertex(1 + max([l[0] for l in lines] + [l[1] for l in lines]))\n",
    "\n",
    "#for each line\n",
    "for i,line in enumerate(lines):\n",
    "    #make a new edge\n",
    "    g.add_edge(g.vertex(int(line[1])),g.vertex(int(line[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d8772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max([l[0] for l in lines] + [l[1] for l in lines])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76494092",
   "metadata": {},
   "source": [
    "## calculate node controllability n<sub>D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffe74b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches, unmatched = modules.bipartiteMatchHK(g, matching={})\n",
    "driver_nodes = set()\n",
    "if len(unmatched) == 0:\n",
    "    print(1/g.num_vertices())\n",
    "else:\n",
    "    print(len(unmatched)/g.num_vertices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c385bd9",
   "metadata": {},
   "source": [
    "## calculate edge controllability n<sub>D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8d63bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#does maximum matching for network in its edge space representation\n",
    "matches, unmatched = modules.bipartiteMatchHK(make_structured_edge_graph(Graph(filter_lone_vertices(g),prune=True)), matching={})\n",
    "\n",
    "#takes the originating node for the driver edges in node space to get to n_D\n",
    "driver_nodes = set()\n",
    "if len(unmatched) == 0:\n",
    "    print(1/n)\n",
    "else:\n",
    "    for i in unmatched:\n",
    "        nodes = i.split('-')\n",
    "        driver_nodes.add(nodes[0])\n",
    "    print(len(driver_nodes)/g.num_vertices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1006d13",
   "metadata": {},
   "source": [
    "# Ownership-USCorp network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745ec480",
   "metadata": {},
   "source": [
    "data downloaded from: http://vlado.fmf.uni-lj.si/pub/networks/data/econ/Eva/Eva.htm (last accessed 11 nov 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b4686d",
   "metadata": {},
   "source": [
    "## Read in data and make network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d0df58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_tool.all import *\n",
    "\n",
    "#opens your file in mode \"read\"\n",
    "f = open(\"ownership.txt\",\"r\")\n",
    "#splits each line into a list of integers\n",
    "lines = [[(int(n)-1) for n in x.split()] for x in f.readlines()]\n",
    "#closes the file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918e6bd6",
   "metadata": {},
   "source": [
    "We make a dictionary to map the company numbers in the text file to a sequential list of numbers for the nodes since the company numbering goes up to 8343 but there are only 7253 unique companies in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a953a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = set([l[0] for l in lines])\n",
    "target = set([l[1] for l in lines])\n",
    "unique_company_numbers = sorted(source.union(target))\n",
    "unique_node_numbers = list(range(0,len(unique_company_numbers)))\n",
    "company_to_node_mapping = dict(zip(unique_company_numbers, unique_node_numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e93b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(unique_node_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1e9aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes the graph\n",
    "g = Graph()\n",
    "#adds enough vertices (the \"1 + \" is for position 0)\n",
    "g.add_vertex(1 + max(unique_node_numbers))\n",
    "\n",
    "#for each line\n",
    "for i,line in enumerate(lines):\n",
    "    #make a new edge\n",
    "    g.add_edge(g.vertex(company_to_node_mapping[int(line[0])]),g.vertex(company_to_node_mapping[int(line[1])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb5e57b",
   "metadata": {},
   "source": [
    "## calculate node controllability n<sub>D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc9da16",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches, unmatched = modules.bipartiteMatchHK((Graph(filter_lone_vertices(g),prune=True)), matching={})\n",
    "driver_nodes = set()\n",
    "if len(unmatched) == 0:\n",
    "    print(1/g.num_vertices())\n",
    "else:\n",
    "    print(len(unmatched)/g.num_vertices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3187d3",
   "metadata": {},
   "source": [
    "## calculate edge controllability n<sub>D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465fd06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#does maximum matching for network in its edge space representation\n",
    "matches, unmatched = modules.bipartiteMatchHK(make_structured_edge_graph(Graph(filter_lone_vertices(g),prune=True)), matching={})\n",
    "\n",
    "#takes the originating node for the driver edges in node space to get to n_D\n",
    "driver_nodes = set()\n",
    "if len(unmatched) == 0:\n",
    "    print(1/n)\n",
    "else:\n",
    "    for i in unmatched:\n",
    "        nodes = i.split('-')\n",
    "        driver_nodes.add(nodes[0])\n",
    "    print(len(driver_nodes)/g.num_vertices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d6119b",
   "metadata": {},
   "source": [
    "# Network simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eebf23e",
   "metadata": {},
   "source": [
    "The networks are generated by passing the right discrete degree distribution generator to the random_graph function in graph_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212ab1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#amount of nodes\n",
    "n=10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe554562",
   "metadata": {},
   "source": [
    "## Erdos-Renyi (poisson degree distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45fa2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import poisson\n",
    "\n",
    "def gen_poisson_pair(mu = 1):\n",
    "    return(poisson.rvs(mu, size=1)[0],poisson.rvs(mu, size=1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2d7071",
   "metadata": {},
   "outputs": [],
   "source": [
    "Poisson_node_n_D = list()\n",
    "Poisson_edge_n_D = list()\n",
    "Poisson_k_mean = list()\n",
    "for mu in [0,0.01,0.05,0.08,0.1,0.15,0.2,0.25,0.3,0.5,0.7,0.9,1,2,3,4,5,6,7,8,9,10]:\n",
    "    G = random_graph(n, lambda : gen_poisson_pair(mu=mu), directed = True)\n",
    "    Poisson_k_mean.append(np.mean(list(G.degree_property_map(deg='total').a)))\n",
    "    matches, unmatched = modules.bipartiteMatchHK(G, matching={})\n",
    "    if len(unmatched) == 0:\n",
    "        Poisson_node_n_D.append(1/n)\n",
    "    else:\n",
    "        Poisson_node_n_D.append(len(unmatched)/n)\n",
    "    \n",
    "    matches, unmatched = modules.bipartiteMatchHK(make_structured_edge_graph(Graph(filter_lone_vertices(G),prune=True)), matching={})\n",
    "    driver_nodes = set()\n",
    "    if len(unmatched) == 0:\n",
    "        Poisson_edge_n_D.append(1/n)\n",
    "    else:\n",
    "        for i in unmatched:\n",
    "            nodes = i.split('-')\n",
    "            driver_nodes.add(nodes[0])\n",
    "        Poisson_edge_n_D.append(len(driver_nodes)/n)\n",
    "        \n",
    "    print('Mean degree: ',Poisson_k_mean[-1])\n",
    "    print('Node n_d: ',Poisson_node_n_D[-1])\n",
    "    print('Edge n_d: ',Poisson_edge_n_D[-1])\n",
    "    print('Writing to file...')\n",
    "\n",
    "    # open a file, where you ant to store the data\n",
    "    file = open('Poisson_node_n_D.pkl', 'wb')\n",
    "\n",
    "    # dump information to that file\n",
    "    pickle.dump(Poisson_node_n_D, file)\n",
    "\n",
    "    # close the file\n",
    "    file.close()\n",
    "\n",
    "    # open a file, where you ant to store the data\n",
    "    file = open('Poisson_edge_n_D.pkl', 'wb')\n",
    "\n",
    "    # dump information to that file\n",
    "    pickle.dump(Poisson_edge_n_D, file)\n",
    "\n",
    "    # close the file\n",
    "    file.close()\n",
    "\n",
    "    # open a file, where you ant to store the data\n",
    "    file = open('Poisson_k_mean.pkl', 'wb')\n",
    "\n",
    "    # dump information to that file\n",
    "    pickle.dump(Poisson_k_mean, file)\n",
    "\n",
    "    # close the file\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e2933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Poisson_node_n_D, Poisson_edge_n_D,Poisson_k_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9088099",
   "metadata": {},
   "source": [
    "## Exponential networks (geometric degree distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde0377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import geom\n",
    "\n",
    "def gen_geom_pair(p = 0.1):\n",
    "    return(geom.rvs(p,loc=-1, size=1)[0],geom.rvs(p,loc=-1, size=1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f78e85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Geom_node_n_D = list()\n",
    "Geom_edge_n_D = list()\n",
    "Geom_k_mean = list()\n",
    "for p in [1,0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1,0.08,0.06,0.04]:\n",
    "    G = random_graph(n, lambda : gen_geom_pair(p=p), directed = True)\n",
    "#     pos = sfdp_layout(G)\n",
    "#     graph_draw(G, pos=pos, output=\"graph-draw-sfdp{}.pdf\".format(p))\n",
    "    Geom_k_mean.append(np.mean(list(G.degree_property_map(deg='total').a)))\n",
    "    matches, unmatched = modules.bipartiteMatchHK(G, matching={})\n",
    "    if len(unmatched) == 0:\n",
    "        Geom_node_n_D.append(1/n)\n",
    "    else:\n",
    "        Geom_node_n_D.append(len(unmatched)/n)\n",
    "    \n",
    "    matches, unmatched = modules.bipartiteMatchHK(make_structured_edge_graph(Graph(filter_lone_vertices(G),prune=True)), matching={})\n",
    "    driver_nodes = set()\n",
    "    if len(unmatched) == 0:\n",
    "        Geom_edge_n_D.append(1/n)\n",
    "    else:\n",
    "        for i in unmatched:\n",
    "            nodes = i.split('-')\n",
    "            driver_nodes.add(nodes[0])\n",
    "        Geom_edge_n_D.append(len(driver_nodes)/n)\n",
    "        \n",
    "    print('Mean degree: ',Geom_k_mean[-1])\n",
    "    print('Node n_d: ',Geom_node_n_D[-1])\n",
    "    print('Edge n_d: ',Geom_edge_n_D[-1])\n",
    "    print('Writing to file...')\n",
    "\n",
    "    # open a file, where you ant to store the data\n",
    "    file = open('Geom_node_n_D.pkl', 'wb')\n",
    "\n",
    "    # dump information to that file\n",
    "    pickle.dump(Geom_node_n_D, file)\n",
    "\n",
    "    # close the file\n",
    "    file.close()\n",
    "\n",
    "    # open a file, where you ant to store the data\n",
    "    file = open('Geom_edge_n_D.pkl', 'wb')\n",
    "\n",
    "    # dump information to that file\n",
    "    pickle.dump(Geom_edge_n_D, file)\n",
    "\n",
    "    # close the file\n",
    "    file.close()\n",
    "\n",
    "    # open a file, where you ant to store the data\n",
    "    file = open('Geom_k_mean.pkl', 'wb')\n",
    "\n",
    "    # dump information to that file\n",
    "    pickle.dump(Geom_k_mean, file)\n",
    "\n",
    "    # close the file\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14727a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "Geom_node_n_D, Geom_edge_n_D, Geom_k_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d4d29c",
   "metadata": {},
   "source": [
    "## Scale-free network (zipf-law degree distribution)\n",
    "Not included in paper because connection to mean degree (\\<k>) not straightforward and simulation-dependent. See Fig S6 in SI of Liu, Slotine, and Barabasi (2011) (https://static-content.springer.com/esm/art%3A10.1038%2Fnature10011/MediaObjects/41586_2011_BFnature10011_MOESM274_ESM.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e171728e",
   "metadata": {},
   "source": [
    "from scipy.stats import zipf\n",
    "\n",
    "def gen_zipf_pair(a = 2.5):\n",
    "    return(zipf.rvs(a, loc=-1,size=1)[0],zipf.rvs(a,loc=-1, size=1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bae598",
   "metadata": {},
   "source": [
    "Zipf_node_n_D = list()\n",
    "Zipf_edge_n_D = list()\n",
    "Zipf_k_mean = list()\n",
    "for a in [5,4,3.7,3.3,3,2.8,2.5,2.3,2,1.8,1.7,1.6,1.5,1.4,1.3]:\n",
    "    G = random_graph(n, lambda : gen_zipf_pair(a=a), directed = True)\n",
    "    Zipf_k_mean.append(np.mean(list(G.degree_property_map(deg='total').a)))\n",
    "    matches, unmatched = modules.bipartiteMatchHK(G, matching={})\n",
    "    if len(unmatched) == 0:\n",
    "        Zipf_node_n_D.append(1/n)\n",
    "    else:\n",
    "        Zipf_node_n_D.append(len(unmatched)/n)\n",
    "    \n",
    "    matches, unmatched = modules.bipartiteMatchHK(make_structured_edge_graph(Graph(filter_lone_vertices(G),prune=True)), matching={})\n",
    "    driver_nodes = set()\n",
    "    if len(unmatched) == 0:\n",
    "        Zipf_edge_n_D.append(1/n)\n",
    "    else:\n",
    "        for i in unmatched:\n",
    "            nodes = i.split('-')\n",
    "            driver_nodes.add(nodes[0])\n",
    "        Zipf_edge_n_D.append(len(driver_nodes)/n)\n",
    "        \n",
    "    print('Mean degree: ',Zipf_k_mean[-1])\n",
    "    print('Node n_d: ',Zipf_node_n_D[-1])\n",
    "    print('Edge n_d: ',Zipf_edge_n_D[-1])\n",
    "    print('Writing to file...')\n",
    "\n",
    "    # open a file, where you ant to store the data\n",
    "    file = open('Zipf_node_n_D_n10000.pkl', 'wb')\n",
    "\n",
    "    # dump information to that file\n",
    "    pickle.dump(Zipf_node_n_D, file)\n",
    "\n",
    "    # close the file\n",
    "    file.close()\n",
    "\n",
    "    # open a file, where you ant to store the data\n",
    "    file = open('Zipf_edge_n_D_n10000.pkl', 'wb')\n",
    "\n",
    "    # dump information to that file\n",
    "    pickle.dump(Zipf_edge_n_D, file)\n",
    "\n",
    "    # close the file\n",
    "    file.close()\n",
    "\n",
    "    # open a file, where you ant to store the data\n",
    "    file = open('Zipf_k_mean_n10000.pkl', 'wb')\n",
    "\n",
    "    # dump information to that file\n",
    "    pickle.dump(Zipf_k_mean, file)\n",
    "\n",
    "    # close the file\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c09c478",
   "metadata": {},
   "source": [
    "Zipf_node_n_D, Zipf_edge_n_D, Zipf_k_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea0b397",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066af5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from graph_tool.all import *\n",
    "import networkx as nx\n",
    "import collections\n",
    "import scipy as sp\n",
    "\n",
    "from scipy.sparse import dok_matrix\n",
    "\n",
    "import modules\n",
    "\n",
    "openmp_set_num_threads(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592a8c1d",
   "metadata": {},
   "source": [
    "## loading in data (optional if above simulations are in memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06826268",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('Geom_k_mean.pkl', 'rb')\n",
    "Geom_k_mean = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "# open a file, where you stored the pickled data\n",
    "file = open('Geom_edge_n_D.pkl', 'rb')\n",
    "# dump information to that file\n",
    "Geom_edge_n_D = pickle.load(file)\n",
    "# close the file\n",
    "file.close()\n",
    "\n",
    "# open a file, where you stored the pickled data\n",
    "file = open('Geom_node_n_D.pkl', 'rb')\n",
    "# dump information to that file\n",
    "Geom_node_n_D = pickle.load(file)\n",
    "# close the file\n",
    "file.close()\n",
    "\n",
    "# open a file, where you stored the pickled data\n",
    "file = open('Poisson_k_mean.pkl', 'rb')\n",
    "# dump information to that file\n",
    "Poisson_k_mean = pickle.load(file)\n",
    "# close the file\n",
    "file.close()\n",
    "\n",
    "# open a file, where you stored the pickled data\n",
    "file = open('Poisson_edge_n_D.pkl', 'rb')\n",
    "# dump information to that file\n",
    "Poisson_edge_n_D = pickle.load(file)\n",
    "# close the file\n",
    "file.close()\n",
    "\n",
    "# open a file, where you stored the pickled data\n",
    "file = open('Poisson_node_n_D.pkl', 'rb')\n",
    "# dump information to that file\n",
    "Poisson_node_n_D = pickle.load(file)\n",
    "# close the file\n",
    "file.close()\n",
    "\n",
    "# # open a file, where you stored the pickled data\n",
    "# file = open('Zipf_k_mean_n10000.pkl', 'rb')\n",
    "# # dump information to that file\n",
    "# Zipf_k_mean = pickle.load(file)\n",
    "# # close the file\n",
    "# file.close()\n",
    "\n",
    "# # open a file, where you stored the pickled data\n",
    "# file = open('Zipf_edge_n_D_n10000.pkl', 'rb')\n",
    "# # dump information to that file\n",
    "# Zipf_edge_n_D = pickle.load(file)\n",
    "# # close the file\n",
    "# file.close()\n",
    "\n",
    "# # open a file, where you stored the pickled data\n",
    "# file = open('Zipf_node_n_D_n10000.pkl', 'rb')\n",
    "# # dump information to that file\n",
    "# Zipf_node_n_D = pickle.load(file)\n",
    "# # close the file\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623b8537",
   "metadata": {},
   "source": [
    "# TODO FINALISEREN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a55ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "xmin = 0\n",
    "xmax = 20\n",
    "ymin = 0\n",
    "ymax = 1\n",
    "# These are the \"Tableau 20\" colors as RGB.    \n",
    "tableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),    \n",
    "             (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),    \n",
    "             (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),    \n",
    "             (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),    \n",
    "             (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]    \n",
    "  \n",
    "# Scale the RGB values to the [0, 1] range, which is the format matplotlib accepts.    \n",
    "for i in range(len(tableau20)):    \n",
    "    r, g, b = tableau20[i]    \n",
    "    tableau20[i] = (r / 255., g / 255., b / 255.)    \n",
    "\n",
    "# You typically want your plot to be ~1.33x wider than tall. This plot is a rare    \n",
    "# exception because of the number of lines being plotted on it.    \n",
    "# Common sizes: (10, 7.5) and (12, 9)    \n",
    "#plt.figure(figsize=(12, 14))\n",
    "plt.figure(figsize=(12, 9)) \n",
    "matplotlib.rcParams['axes.linewidth'] = 2\n",
    "\n",
    "  \n",
    "# Remove the plot frame lines. They are unnecessary chartjunk.    \n",
    "ax = plt.subplot(111)    \n",
    "# ax.spines[\"top\"].set_visible(False)    \n",
    "# ax.spines[\"bottom\"].set_visible(False)    \n",
    "# ax.spines[\"right\"].set_visible(False)    \n",
    "# ax.spines[\"left\"].set_visible(False)\n",
    "  \n",
    "# Ensure that the axis ticks only show up on the bottom and left of the plot.    \n",
    "# Ticks on the right and top of the plot are generally unnecessary chartjunk.    \n",
    "ax.get_xaxis().tick_bottom()    \n",
    "ax.get_yaxis().tick_left()    \n",
    "  \n",
    "# Limit the range of the plot to only where the data is.    \n",
    "# Avoid unnecessary whitespace.    \n",
    "plt.ylim(ymin, ymax)    \n",
    "plt.xlim(xmin, xmax)    \n",
    "  \n",
    "# Make sure your axis ticks are large enough to be easily read.    \n",
    "# You don't want your viewers squinting to read your plot.    \n",
    "plt.yticks(np.arange(ymin, ymax+0.25, 0.25), [str(np.round(x,3)) + \"\" for x in np.arange(ymin, ymax+0.25, 0.25)], fontsize=18)\n",
    "plt.xticks(np.arange(xmin, xmax+5, 5), [str(np.round(x,1)) + \"\" for x in np.arange(xmin, xmax+5,5)], fontsize=18)    \n",
    "\n",
    "plt.plot(range(xmin, xmax+1), [0.5] * len(range(xmin, xmax+1)), \"--\", lw=2, color=\"black\", alpha=0.8)\n",
    "\n",
    "#Remove the tick marks; they are unnecessary with the tick lines we just plotted.    \n",
    "plt.tick_params(axis=\"both\", which=\"both\", bottom=\"on\", top=\"off\",    \n",
    "                labelbottom=\"on\", left=\"off\", right=\"off\", labelleft=\"on\") \n",
    "\n",
    "# Now that the plot is prepared, it's time to actually plot the data!    \n",
    "plt.scatter(Poisson_k_mean,Poisson_node_n_D,marker='x',s=100,alpha=1,lw=1, color=tableau20[0])\n",
    "plt.scatter(Geom_k_mean,Geom_node_n_D,marker='o',s=50,alpha=1,lw=1, color=tableau20[6])\n",
    "\n",
    "plt.plot(Poisson_k_mean,Poisson_node_n_D,'-',lw=3,alpha=.4, color=tableau20[0], label = 'Poisson node control')\n",
    "plt.plot(Geom_k_mean,Geom_node_n_D,'-',lw=3,alpha=.4, color=tableau20[6], label = 'Exp node control')\n",
    "\n",
    "\n",
    "plt.scatter(Poisson_k_mean,Poisson_edge_n_D,marker='x',s=100,alpha=1, lw=1, color=tableau20[0])\n",
    "plt.scatter(Geom_k_mean,Geom_edge_n_D,marker='o',s=50,alpha=1, lw=1, color=tableau20[6])\n",
    "\n",
    "plt.plot(Poisson_k_mean,Poisson_edge_n_D,'--',lw=3,alpha=.4, color=tableau20[0], label = 'Poisson edge control')\n",
    "plt.plot(Geom_k_mean,Geom_edge_n_D,'--',lw=3,alpha=.4, color=tableau20[6], label = 'Exp edge control')\n",
    "\n",
    "## matplotlib's title() call centers the title on the plot, but not the graph,    \n",
    "# so I used the text() call to customize where the title goes.    \n",
    "  \n",
    "# Make the title big enough so it spans the entire plot, but don't make it    \n",
    "# so big that it requires two lines to show.\n",
    "ax.tick_params(top=False)\n",
    "ax.tick_params(right=False)\n",
    "  \n",
    "# Note that if the title is descriptive enough, it is unnecessary to include    \n",
    "# axis labels; they are self-evident, in this plot's case.    \n",
    "#plt.text(xmin + (xmax-xmin)/2, ymax+ 0.2, \"Percentage income increase of person in 75th percentile of starting wealth \\n vs person in 25th percentile, for different controls (3-10 years into one's career)\", fontsize=17, ha=\"center\")    \n",
    "#plt.title(\"Percentage income difference for different personal characteristics (3-10 years into one's career)\")    \n",
    "plt.ylabel('$n_D$', fontsize=18)\n",
    "plt.xlabel(r'$\\langle k \\rangle$',fontsize=18)\n",
    "plt.legend(prop={'size': 16}, frameon=False)\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Palatino\"],\n",
    "    \"font.weight\": 700,\n",
    "})\n",
    "# Finally, save the figure as a PNG.    \n",
    "# You can also save it as a PDF, JPEG, etc.    \n",
    "# Just change the file extension in this call.    \n",
    "# bbox_inches=\"tight\" removes all the extra whitespace on the edges of your plot.    \n",
    "plt.savefig(\"control_diff.pdf\", bbox_inches='tight')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d26466",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
